{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be10c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook', font_scale=1.2, rc={'lines.linewidth':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis, skew, mode, boxcox\n",
    "import statistics as sta\n",
    "import datetime as dt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379da10c",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a68d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Homework/Data/finalData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b78c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Transactions were made from {} to {}'.format(df['OrderDate'].min(), df['OrderDate'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b680a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result of distinct value:\\n\", df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc1b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalValue'] = df['OrderQty']*(1 - df['UnitPriceDiscount'])*df['UnitPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a05713",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['TotalValue'] - df['LineTotal']).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e117f7",
   "metadata": {},
   "source": [
    "Because the subtraction between each row of TotalValue and LineTotal is almost 0, we can assume that LineTotal contains final value of transactions, which will be used to calculate Monetary factor later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421905d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('TotalValue', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OrderDate'] = pd.to_datetime(df['OrderDate'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e997d6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['OrderDate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705267ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['CustomerID']==11000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce501f",
   "metadata": {},
   "source": [
    "For a random customer, we see that if he/she bought more than one product, the SalesOrderID and OrderDate will be duplicated for each ProductID. However, when counting Frequency, we still recognize that this customer made 3 unique purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datemark = dt.datetime(2021,12,26)\n",
    "df['Recency'] = df['OrderDate']\n",
    "rfm = df.groupby('CustomerID').agg({'Recency': lambda date: (datemark - date.max()).days,\n",
    "                                    'T': lambda date: (datemark - date.min()).days,\n",
    "                                    'SalesOrderID': lambda num: num.nunique(),\n",
    "                                    'LineTotal': lambda price: price.sum()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69903211",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm = rfm.rename(columns={'SalesOrderID': 'Frequency', 'LineTotal': 'Monetary'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9807cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e3645",
   "metadata": {},
   "source": [
    "# TRADITIONAL RFM MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a5cbaa",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656f670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Result of duplicated: \", rfm.duplicated().sum())\n",
    "print(\"-------------\")\n",
    "print(\"Result of missing value: \", rfm.isnull().values.sum())\n",
    "print(\"-------------\")\n",
    "print(\"Result of distinct value:\\n\", rfm.nunique())\n",
    "print(\"-------------\")\n",
    "\n",
    "#boxplot\n",
    "list_num =['Recency','Frequency','Monetary']\n",
    "for col in list_num:\n",
    "    plt.boxplot(rfm[col], vert=False, notch=True, flierprops=dict(markerfacecolor='orange', marker='s'))\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "\n",
    "for column in ['Recency', 'Frequency', 'Monetary']:\n",
    "    print(f\"Sample Variance: {np.var(rfm[column])}\")\n",
    "    \n",
    "    print(f\"SE:\", np.std(rfm[column], ddof=1) / np.sqrt(np.size(rfm[column])))\n",
    "    print(f\"Mode: {mode(rfm[column])}\")\n",
    "    print(f\"Median: {sta.median(rfm[column])}\")\n",
    "\n",
    "    print(f\"Skewness: {skew(rfm[column], bias = False)}\")\n",
    "    print(f\"Kurtosis: {kurtosis(rfm[column], bias = False)}\")\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a904ddc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in ['Recency','Frequency','Monetary']:\n",
    "    q25, q75 = np.percentile(rfm[i], 25), np.percentile(rfm[i], 75)\n",
    "    iqr = q75 - q25\n",
    "    print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    # identify outliers\n",
    "    outliers = [x for x in rfm[i] if x < lower or x > upper]\n",
    "    print('Identified outliers: %d' % len(outliers))\n",
    "    # non-outliers\n",
    "    non_outliers = [x for x in rfm[i] if x >= lower and x <= upper]\n",
    "    print('Non-outlier observations: %d' % len(non_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44acb3",
   "metadata": {},
   "source": [
    "The percentage of outliers in each column is in range between 2.4% and 4.4%. However, we decide to keep them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bb23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = rfm[['Recency', 'Frequency', 'Monetary']].quantile(q=[0.2, 0.4, 0.6, 0.8]).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c648c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ad3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_score(x):\n",
    "    if x <= quantiles['Recency'][.2]:\n",
    "        return 5\n",
    "    elif x <= quantiles['Recency'][.4]:\n",
    "        return 4\n",
    "    elif x <= quantiles['Recency'][.6]:\n",
    "        return 3\n",
    "    elif x <= quantiles['Recency'][.8]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def fm_score(x, c):\n",
    "    if x <= quantiles[c][.2]:\n",
    "        return 1\n",
    "    elif x <= quantiles[c][.4]:\n",
    "        return 2\n",
    "    elif x <= quantiles[c][.6]:\n",
    "        return 3\n",
    "    elif x <= quantiles[c][.8]:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5    \n",
    "\n",
    "rfm['R'] = rfm['Recency'].apply(lambda x: r_score(x))\n",
    "rfm['F'] = rfm['Frequency'].apply(lambda x: fm_score(x, 'Frequency'))\n",
    "rfm['M'] = rfm['Monetary'].apply(lambda x: fm_score(x, 'Monetary'))\n",
    "rfm['RFM_Segment'] = rfm['R'].map(str) + rfm['F'].map(str) + rfm['M'].map(str)\n",
    "rfm['RFM_Score'] = rfm[['R', 'F', 'M']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.groupby('RFM_Segment').agg({'Recency': 'mean', 'Frequency': 'mean', 'Monetary': ['mean', 'count']}).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ac9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "segt_map = {\n",
    "    r'[1-2][1-2]': 'hibernating',\n",
    "    r'[1-2][3-4]': 'at risk',\n",
    "    r'[1-2]5': 'can\\'t loose',\n",
    "    r'3[1-2]': 'about to sleep',\n",
    "    r'33': 'need attention',\n",
    "    r'[3-4][4-5]': 'loyal customers',\n",
    "    r'41': 'promising',\n",
    "    r'51': 'new customers',\n",
    "    r'[4-5][2-3]': 'potential loyalists',\n",
    "    r'5[4-5]': 'champions'\n",
    "}\n",
    "\n",
    "rfm['Segment'] = rfm['R'].map(str) + rfm['F'].map(str)\n",
    "rfm['Segment'] = rfm['Segment'].replace(segt_map, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17095244",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_plot = rfm.groupby('Segment').agg(customers=('CustomerID', 'count'), min_rfm=('RFM_Segment', 'min'), max_rfm=('RFM_Segment', 'max')).sort_values(by='customers', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07636c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b5a3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "treemap = rfm.groupby('Segment').agg(customers=('CustomerID', 'count')).reset_index()\n",
    "import squarify\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(35, 15), dpi=300)\n",
    "labels=treemap['Segment']\n",
    "ax = squarify.plot(sizes=treemap['customers'], label=labels, alpha=1, text_kwargs={'color': 'black', 'size': 25},\n",
    "              color=plt.cm.RdYlGn(np.linspace(0, 1, len(labels))), ec='black', norm_x=145, norm_y=90)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bars = plt.barh(width=rfm_plot['customers'], y=list(rfm_plot['Segment'].values), color='silver')\n",
    "for i, bar in enumerate(bars):\n",
    "    if rfm['Segment'].value_counts().index[i] in ['loyal customers', 'champions']:\n",
    "        bar.set_color('orange')\n",
    "plt.title('Number of customers per segmentation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46589d85",
   "metadata": {},
   "source": [
    "# KMEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3cf663",
   "metadata": {},
   "source": [
    "## DATA TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966a1c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution before transformation\n",
    "plt.figure(figsize=(9, 12))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Distribution of Recency')\n",
    "sns.distplot(rfm['Recency'], hist_kws=dict(edgecolor=\"k\", linewidth=1.2))\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Distribution of Frecency')\n",
    "sns.distplot(rfm['Frequency'], hist_kws=dict(edgecolor=\"k\", linewidth=1.2))\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Distribution of Monetary')\n",
    "sns.distplot(rfm['Monetary'], hist_kws=dict(edgecolor=\"k\", linewidth=1.2))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation process to get the skewness close to 0\n",
    "# Log transformation\n",
    "rfm_log = rfm.copy()\n",
    "rfm_log = np.log(rfm_log[['Recency','Frequency','Monetary']])\n",
    "# Square root transformation\n",
    "rfm_sqrt = rfm.copy()\n",
    "rfm_sqrt = np.sqrt(rfm_sqrt[['Recency','Frequency','Monetary']])\n",
    "# Cube root transformation\n",
    "rfm_cbrt = rfm.copy()\n",
    "rfm_cbrt = np.cbrt(rfm_cbrt[['Recency','Frequency','Monetary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_skew(df, column):\n",
    "    skewness = skew(df[column])\n",
    "    plt.title('Distribution of ' + column)\n",
    "    sns.distplot(df[column], hist_kws=dict(edgecolor=\"k\", linewidth=1.2))\n",
    "    print(\"{}'s skew: {}\".format(column, skewness))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827c2a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Square root transformation\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "check_skew(rfm_sqrt,'Recency')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "check_skew(rfm_sqrt,'Frequency')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "check_skew(rfm_sqrt,'Monetary')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61109082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cube root transformation\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "check_skew(rfm_cbrt,'Recency')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "check_skew(rfm_cbrt,'Frequency')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "check_skew(rfm_cbrt,'Monetary')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d387684d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Log transformation\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "check_skew(rfm_log,'Recency')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "check_skew(rfm_log,'Frequency')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "check_skew(rfm_log,'Monetary')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a2769",
   "metadata": {},
   "source": [
    "It is clear that log-transformation gives us the skewness closest to 0. As a result, log-transformation will be chosen as a method to transform our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(rfm_log)\n",
    "rfm_scaled = scaler.transform(rfm_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72039ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_scaled = pd.DataFrame(rfm_scaled, columns=rfm_log.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0609cf3",
   "metadata": {},
   "source": [
    "## FIND THE OPTIMAL K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad177b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ebf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = [] \n",
    "for k in range(1, 12):\n",
    "    km = KMeans(n_clusters=k, random_state=1)\n",
    "    km.fit(rfm_scaled)\n",
    "    inertias.append(km.inertia_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef839f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(1, 12), inertias, 'bx-') \n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Inertia') \n",
    "plt.title('The Elbow Method using Inertia') \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87348922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "km = KMeans(random_state=42)\n",
    "visualizer = KElbowVisualizer(km, k=(2, 12))\n",
    "visualizer.fit(rfm_scaled)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f31c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "fig, ax = plt.subplots(3, 2, figsize=(15, 8))\n",
    "for i in range(6, 10):\n",
    "    km = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    q, mod = divmod(i, 2)\n",
    "    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(rfm_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de87f1e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sh_score = []\n",
    "for i in range(2, 12):\n",
    "    km = KMeans(n_clusters = i, random_state=1)\n",
    "    km.fit_predict(rfm_scaled)\n",
    "    score = silhouette_score(rfm_scaled, km.labels_, metric='euclidean')\n",
    "    sh_score.append(score)\n",
    "\n",
    "plt.plot(sh_score)\n",
    "plt.xticks(np.arange(10), range(2, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d22eff",
   "metadata": {},
   "source": [
    "## VISUALIZE SEGMENTATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def kmeans(df, clusters_num):\n",
    "    km = KMeans(n_clusters = clusters_num, random_state=1)\n",
    "    y_clusters = km.fit_predict(df)\n",
    "    print(f\"Silhouette Score for {clusters_num}:\", \"%1.2f\" % silhouette_score(rfm_scaled, clusters))\n",
    "    # print(kmean.labels_)\n",
    "    # print(kmean.cluster_centers_)\n",
    "    fig = px.scatter_3d(df, x=\"Recency\", y=\"Frequency\", z=\"Monetary\", color = clusters + 1, size = clusters + 1)\n",
    "    # color, size increment to 1 to have the calibration starting from 1, instead of zero\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ec399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane = dict(xaxis = dict(title  = 'Recency -->'), yaxis = dict(title  = 'Frequency --->'),zaxis = dict(title  = 'Monetary-->'))\n",
    "import plotly.graph_objects as go\n",
    "def kmeans(df, clusters_num):\n",
    "    km = KMeans(n_clusters = clusters_num, random_state=1)\n",
    "    labels = km.labels_\n",
    "    trace = go.Scatter3d(x=x[:, 0], y=x[:, 1], z=x[:, 2], mode='markers',marker=dict(color=labels, size=10, line=dict(color='black', width=10)))\n",
    "    layout = go.Layout(margin=dict(l=0, r=0), scene=plane, height=800, width=800)\n",
    "    data = [trace]\n",
    "    fig = go.Figure(data = data, layout = layout)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14571403",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters = 4, random_state=1)\n",
    "km.fit_predict(rfm_scaled)\n",
    "labels = km.labels_\n",
    "trace = go.Scatter3d(x=x[:, 0], y=x[:, 1], z=x[:, 2], mode='markers',marker=dict(color=labels, size=10, line=dict(color='black', width=10)))\n",
    "layout = go.Layout(margin=dict(l=0, r=0), scene=plane, height=800, width=800)\n",
    "data = [trace]\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8fb92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans(rfm_scaled, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bcde1e",
   "metadata": {},
   "source": [
    "# CUSTOMER LIFETIME VALUE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca5e77",
   "metadata": {},
   "source": [
    "- The CLTV account has many calculation metrics. Basically, the metrics to focus on: Average Order Value, Purchase Frequency, Profit Margin, Churn Rate, Customer Value, Customer Life Time Value.\n",
    "- Formula:\n",
    "\n",
    "   $CLTV = (Customer Value  /  Churn Rate) * Profit Margin$\n",
    "   \n",
    "   $Customer Value = Average Order Value * Purchase Frequency$\n",
    "   \n",
    "   $Average Order Value = Total Revenue * Total Number of Orders$\n",
    "   \n",
    "   $Purchase Frequency = Total Number of Orders  /  Total Number of Customers$\n",
    "   \n",
    "   $Profit Margin = Total Price  /  Profit Rate$\n",
    "   \n",
    "   $Churn Rate = 1 - Repeat Rate$\n",
    "   \n",
    "   $Repeat Rate = Number of Customers Who have Shopped more than Once / Total Number of Customers$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a77d8",
   "metadata": {},
   "source": [
    "## COHORT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d2b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['month'] = df['OrderDate'].dt.month\n",
    "df['year'] = df['OrderDate'].dt.year\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec763fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['cohort'] = df.apply(lambda row: row['year'] * 100 + row['month'], axis=1)\n",
    "cohorts = df.groupby('CustomerID')['cohort'].min().reset_index()\n",
    "print(cohorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b96426",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts.columns = ['CustomerID', 'first_cohort']\n",
    "df = df.merge(cohorts, on='CustomerID', how='left')\n",
    "\n",
    "headers = df['cohort'].value_counts().reset_index()\n",
    "headers.columns = ['Cohorts', 'Count']\n",
    "headers = headers.sort_values(['Cohorts'])['Cohorts'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cohort_distance'] = df.apply(lambda row: (headers.index(row['cohort']) - headers.index(row['first_cohort'])) if (row['first_cohort'] != 0 and row['cohort'] != 0) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeae966",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_pivot = pd.pivot_table(df, index='first_cohort', columns='cohort_distance', values='CustomerID', aggfunc=pd.Series.nunique)\n",
    "cohort_pivot = cohort_pivot.div(cohort_pivot[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71f04b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cohort_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec967a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30, 30))\n",
    "y_labels = [str(int(header) % 100) + '-' + str(int(header) / 100) for header in headers]\n",
    "x_labels = range(0, len(y_labels))\n",
    "plt.yticks(ticks=headers, labels=y_labels)\n",
    "plt.xticks(x_labels, x_labels)\n",
    "ax.set(xlabel='Months After First Purchase', ylabel='First Purchase Cohort')\n",
    "plt.title(\"Cohort Analysis\", fontsize=20)\n",
    "sns.heatmap(cohort_pivot, annot=True, fmt='.0%', mask=cohort_pivot.isnull(), ax=ax, square=True, linewidths=1, cmap=sns.cubehelix_palette(rot=-.4))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b585bf",
   "metadata": {},
   "source": [
    "## PARETO/NBD COMBINED WITH GAMMA - GAMMA MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e50ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm[['Frequency', 'Monetary']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5613f",
   "metadata": {},
   "source": [
    "The Gamma-Gamma model is based on the assumption that the number of transactions does not depend on their monetary value.\n",
    "The frequency and monetary value are not correlated if the output is close to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e87fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm = rfm[rfm['Monetary'] > 0]\n",
    "from lifetimes import ParetoNBDFitter\n",
    "pareto_nbd = ParetoNBDFitter(penalizer_coef = 0.0)\n",
    "pareto_nbd.fit(rfm[\"Frequency\"], rfm[\"Recency\"], rfm[\"T\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes.plotting import plot_frequency_recency_matrix\n",
    "from lifetimes.plotting import plot_probability_alive_matrix\n",
    "from lifetimes.plotting import plot_period_transactions\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_frequency_recency_matrix(pareto_nbd)\n",
    "plot_probability_alive_matrix(pareto_nbd)\n",
    "plot_period_transactions(pareto_nbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm[\"p_not_alive\"] = 1-pareto_nbd.conditional_probability_alive(rfm[\"Frequency\"], rfm[\"Recency\"], rfm[\"T\"])\n",
    "rfm[\"p_alive\"] = pareto_nbd.conditional_probability_alive(rfm[\"Frequency\"], rfm[\"Recency\"], rfm[\"T\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a168b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm[\"predicted_purchases\"] = pareto_nbd.conditional_expected_number_of_purchases_up_to_time(30, rfm[\"Frequency\"], rfm[\"Recency\"], rfm[\"T\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c67dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.sort_values(by = \"predicted_purchases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fabfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
